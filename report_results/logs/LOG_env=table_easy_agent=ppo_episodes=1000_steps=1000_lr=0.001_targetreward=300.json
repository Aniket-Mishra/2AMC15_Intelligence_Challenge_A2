{
  "agent": "ppo",
  "agent_config": {
    "state_dim": 3,
    "action_dim": 3,
    "gamma": 0.99,
    "clip_epsilon": 0.1,
    "update_epochs": 10,
    "batch_size": 64,
    "gae_lambda": 0.95,
    "lr": 0.001
  },
  "timestamp": "20250624_202753",
  "episodes": 1000,
  "max_steps": 1000,
  "seed": 42,
  "success_rate": 0.995,
  "avg_reward_last_50": 103.23200000000001,
  "final_eval_steps": 54,
  "reward_file": "results_common/rewards/METRICS_env=table_easy_agent=ppo_episodes=1000_steps=1000_lr=0.001_targetreward=300.csv",
  "path_file": "results_common/graph_path/GRAPH_env=table_easy_agent=ppo_episodes=1000_steps=1000_lr=0.001_targetreward=300.npy",
  "reward_plot_png": "results_common/graphs/METRICS_env=table_easy_agent=ppo_episodes=1000_steps=1000_lr=0.001_targetreward=300.png",
  "path_plot_png": "results\\PATH_env=table_easy_agent=ppo_episodes=1000_steps=1000_lr=0.001_targetreward=300.png",
  "EVALUATION STEPS": 55,
  "CONVERGENCE EPISODE": 192
}