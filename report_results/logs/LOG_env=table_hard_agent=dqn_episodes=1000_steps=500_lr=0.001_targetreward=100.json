{
  "agent": "dqn",
  "agent_config": {
    "state_dim": 3,
    "action_dim": 3,
    "epsilon_start": 1.0,
    "epsilon_end": 0.01,
    "epsilon_decay": 54286,
    "lr": 0.001
  },
  "timestamp": "20250624_034548",
  "episodes": 1000,
  "max_steps": 500,
  "seed": 42,
  "success_rate": 0.834,
  "avg_reward_last_50": -510.2880000000028,
  "final_eval_steps": 500,
  "reward_file": "results_common/rewards/METRICS_env=table_hard_agent=dqn_episodes=1000_steps=500_lr=0.001_targetreward=100.csv",
  "path_file": "results_common/graph_path/GRAPH_env=table_hard_agent=dqn_episodes=1000_steps=500_lr=0.001_targetreward=100.npy",
  "reward_plot_png": "results_common/graphs/METRICS_env=table_hard_agent=dqn_episodes=1000_steps=500_lr=0.001_targetreward=100.png",
  "path_plot_png": "results\\PATH_env=table_hard_agent=dqn_episodes=1000_steps=500_lr=0.001_targetreward=100.png",
  "EVALUATION STEPS": 501,
  "CONVERGENCE EPISODE": 337
}